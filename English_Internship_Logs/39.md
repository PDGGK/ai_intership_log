# Technical Learning Log

## 2023-12-28 Technical Learning Log

<div align="center">
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white"/>
  <img src="https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white"/>
  <img src="https://img.shields.io/badge/Regex-2496ED?style=for-the-badge&logo=regex&logoColor=white"/>
  <img src="https://img.shields.io/badge/Web_Scraping-FF6B6B?style=for-the-badge&logo=python&logoColor=white"/>
</div>

# Python Automation for Old Residential Community Analysis: A Practical Guide from Address Extraction to Data Analysis

<div align="center">
  <p><strong>Efficient Identification and Analysis of Old Residential Communities for Urban Renewal</strong></p>
  <p>🔍 Intelligent Address Parsing | 📊 Data Collection | 🏘️ Community Identification | 📈 Automated Analysis</p>
</div>

---

## 📑 Table of Contents

- [📘 Introduction](#1-introduction-)
- [💻 Core Technology Implementation](#2-core-technology-implementation-)
- [📋 Case Study](#3-case-study-)
- [🌟 Best Practices](#4-best-practices-)
- [📝 Summary and Outlook](#5-summary-and-outlook-)

---

## 1. Introduction <img src="https://img.shields.io/badge/Introduction-FF6B6B?style=flat-square&logo=bookstack&logoColor=white"/>

In the context of urban renewal and renovation of old residential communities, quickly and accurately identifying and analyzing information about these communities has become increasingly important. This article will detail how to develop an automated tool using Python to identify old residential communities by analyzing address information and obtaining key data such as construction years from online sources.

### 1.1 Project Background 🏘️

- Growing demand for renovation of old residential communities
- Low efficiency of manual data collection and analysis
- Need for automated tools to improve work efficiency
- Scattered data sources requiring integration from multiple channels

### 1.2 Technology Selection ⚙️

- Python as the main development language
- Web scraping technology to obtain community information
- Regular expressions for text data processing
- Pandas for data analysis and export

---

## 2. Core Technology Implementation <img src="https://img.shields.io/badge/Core_Tech-2196F3?style=flat-square&logo=code&logoColor=white"/>

### 2.1 Community Name Extraction 🔍

Accurate extraction of community names is the foundation of the entire analysis process. We adopt a multi-level extraction strategy:

```python
def extract_community_name(self, address: str) -> str:
    """Optimized community name extraction"""
    # Define community keywords
    community_keywords = ['garden', 'community', 'plaza', 'home', 'court', 'village', 'apartment', 'villa', 'city']
    
    # 1. First try to match complete community names
    for keyword in community_keywords:
        pattern = f'([^0-9road street lane]{1,20}?{keyword})'
        match = re.search(pattern, address)
        if match:
            community = match.group(1)
            # Clean up house numbers
            community = re.sub(r'^\d+no\.', '', community)
            return community.strip()

    # 2. Check if address ends with "village"
    village_match = re.search(r'([^\d]+village)[^\d]*$', address)
    if village_match:
        return village_match.group(1)

    # 3. Extract road name
    road_match = re.search(r'([^province city district county town village\d]+?[road street])', address)
    if road_match:
        return road_match.group(1)

    return address
```

Key points of the extraction strategy:
1. Priority matching of community names with keywords
2. Secondary matching of village names
3. Finally extracting road information
4. Removing excess information such as house numbers

### 2.2 Data Acquisition and Analysis 📊

To obtain information about the construction year of communities, we developed a specialized data acquisition class:

```python
class LianjiaAnalyizer:
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 13_2_3 like Mac OS X)',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9'
        }
        self.old_community_year = 2010

    def get_community_info(self, community_name: str) -> Dict:
        try:
            search_url = f"https://m.ke.com/changzhou/xiaoqu/rs{quote(community_name)}/"
            response = requests.get(search_url, headers=self.headers, timeout=10)
            
            # Match community link
            detail_pattern = r'href="(/changzhou/xiaoqu/\d+/)"'
            matches = re.findall(detail_pattern, response.text)
            
            if matches:
                detail_url = f"https://m.ke.com{matches[0]}"
                detail_response = requests.get(detail_url, headers=self.headers)
                
                # Extract construction year
                year_pattern = r'Construction Year</div><div[^>]*>(\d{4})[year-](\d{4})?year?'
                year_match = re.search(year_pattern, detail_response.text)
                
                if year_match:
                    start_year = int(year_match.group(1))
                    end_year = int(year_match.group(2)) if year_match.group(2) else start_year
                    return {
                        "Construction Year": f"{start_year}-{end_year}",
                        "Earliest Construction": start_year
                    }
            return {}
            
        except Exception as e:
            print(f"Error getting community information: {e}")
            return {}
```

Key technical points:
1. Simulating mobile requests for better compatibility
2. Using regular expressions to extract year information
3. Handling year ranges (e.g., 2000-2008)
4. Comprehensive error handling mechanisms

### 2.3 Data Analysis and Export 📈

Using Pandas for data processing and analysis:

```python
def analyze_communities(filename: str, limit: int = 10) -> pd.DataFrame:
    """Analyze community list"""
    analyzer = LianjiaAnalyzer()
    results = []
    
    with open(filename, 'r', encoding='utf-8') as f:
        addresses = [line.strip() for line in f if line.strip()][:limit]
    
    for idx, address in enumerate(addresses, 1):
        result = analyzer.analyze_community(address)
        results.append(result)
        time.sleep(2)  # Control request frequency
        
    return pd.DataFrame(results)
```

---

## 3. Case Study <img src="https://img.shields.io/badge/Case_Study-4CAF50?style=flat-square&logo=experiment&logoColor=white"/>

### 3.1 Test Data Analysis 🧪

Here are some typical address examples and their processing results:

- Original address: `Labor West Road No. 99 New World Garden 2-5`
- Extraction result: `New World Garden`

- Original address: `Yanzheng West Avenue No. 325 Lakeside Spring and Autumn Garden District 22 Building 202`
- Extraction result: `Lakeside Spring and Autumn Garden`

- Original address: `South Xiashu Street Sanhe Village Committee Jinjiatan No. 71`
- Extraction result: `Jinjiatan Village`

### 3.2 Practical Application Effects ✨

The program can automatically complete the following tasks:
1. Batch process address lists
2. Extract valid community names
3. Obtain construction year information
4. Determine if it is an old residential community
5. Generate analysis reports

---

## 4. Best Practices <img src="https://img.shields.io/badge/Best_Practices-FFA000?style=flat-square&logo=lightbulb&logoColor=white"/>

### 4.1 Data Acquisition 🌐

1. Reasonably control request frequency to avoid being banned
2. Use request headers to simulate normal browser behavior
3. Implement error retry mechanisms
4. Save intermediate data to avoid repeated requests

### 4.2 Data Processing 🔧

1. Standardize data cleaning processes
2. Establish comprehensive error handling mechanisms
3. Save detailed processing logs
4. Regularly verify data accuracy

### 4.3 System Optimization 🚀

1. Implement data caching mechanisms
2. Optimize regular expression matching efficiency
3. Support breakpoint resumption
4. Add data validation mechanisms

---

## 5. Summary and Outlook <img src="https://img.shields.io/badge/Summary-FF5722?style=flat-square&logo=target&logoColor=white"/>

This article introduced an automated analysis tool for old residential communities developed using Python, mainly covering the following aspects:

1. Address Information Extraction 📍: Intelligent extraction using regular expressions
2. Data Acquisition 🔍: Obtaining community information through web scraping
3. Data Analysis 📊: Data processing using Pandas
4. Result Output 📑: Generating Excel reports

### Future Optimization Directions 🔮:

1. Support more data sources 📚
2. Improve address matching accuracy 🎯
3. Add visualization analysis functions 📈
4. Develop a web interface 💻
5. Support batch processing of large-scale data 📦
6. Integrate with geographic information systems 🗺️

This project provides strong technical support for urban renewal and renovation of old residential communities, improving work efficiency through automation and providing data support for relevant decision-making.

---

<div align="center">
  <p><small>© 2023 Old Community Analysis Project | Document Version v1.0</small></p>
</div> 